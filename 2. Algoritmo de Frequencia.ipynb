{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affc0ece",
   "metadata": {},
   "source": [
    "## 1. Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b1d61c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import json\n",
    "import math\n",
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import string\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647ff5de",
   "metadata": {},
   "source": [
    "## 2. Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107b2bb0",
   "metadata": {},
   "source": [
    "### 2.1. Definição da função de Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e40c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(texto):\n",
    "    return \"\".join(c for c in texto if ord(c) < 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9b645f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(texto):\n",
    "    return \"\".join(c for c in texto if c.isalnum() or c.isspace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d9bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_digits(texto):\n",
    "    return \"\".join(c for c in texto if not c.isdigit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699809c2",
   "metadata": {},
   "source": [
    "A função **preprocessamento** faz a limpeza no texto removendo todos os caracteres que devem ser desconsiderados no processo de geração de tokens de sentenças e palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47802f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c84293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessamento(texto):\n",
    "    # Lista de palavras irrelevantes para a etapa de processamento do texto.\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "    # Lista de sinais de pontuação\n",
    "    punctuation = string.punctuation\n",
    "\n",
    "    #pln = spacy.load('en_core_web_sm')\n",
    "\n",
    "    texto = texto.lower()\n",
    "    texto = remove_non_ascii(texto)\n",
    "    texto = remove_special_characters(texto)\n",
    "    texto = remove_digits(texto)\n",
    "    \n",
    "    #doc = pln(texto)\n",
    "    \n",
    "    tokens = []\n",
    "    # Pré-processamento sem a lematização\n",
    "    for token in nltk.word_tokenize(texto):\n",
    "        tokens.append(token)\n",
    "    \n",
    "    # Pré-processamento com a lematização\n",
    "    #for token in documento:\n",
    "        #tokens.append(token.lemma_)\n",
    "\n",
    "    # Filtrar apenas as palavras que não estiverem na lista de stopwords e nem na lista de pontuações\n",
    "    tokens = [palavra for palavra in tokens if palavra not in stopwords and palavra not in punctuation]\n",
    "    \n",
    "    # Converter a lista de palavras para uma String, não adiciona valores numéricos\n",
    "    texto = ' '.join([str(elemento) for elemento in tokens if not elemento.isdigit()])\n",
    "\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05af7e0c",
   "metadata": {},
   "source": [
    "### 2.2. Definição das funções de tokenização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3869fe",
   "metadata": {},
   "source": [
    "A função **token_sentences** transforma cada sentença do texto original em um token. Cada frase do texto, é considerado um token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eae0f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma cada frase do texto original em um token.\n",
    "def token_sentences(texto):\n",
    "    sentencas_originais = [sentenca for sentenca in nltk.sent_tokenize(texto)]\n",
    "    \n",
    "    return sentencas_originais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7841bde",
   "metadata": {},
   "source": [
    "A função **preprocessing_sentences** recebe uma lista de sentenças com o texto original e executa a função de preprocessamento, eliminando caracteres especiais, sinais de pontuação, dígitos, stop words, etc. Essa função retorna uma lista de sentenças formatadas (pré-processadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f14f5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento das sentenças originais\n",
    "def preprocessing_sentences(sentencas_originais):\n",
    "    sentencas_formatadas = [preprocessamento(sentenca_original) for sentenca_original in sentencas_originais]\n",
    "    \n",
    "    return sentencas_formatadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f5182f",
   "metadata": {},
   "source": [
    "## 3. Algoritmo Baseado em Frequência"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef85865",
   "metadata": {},
   "source": [
    "### 3.1. Definição da função summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eefe0d8",
   "metadata": {},
   "source": [
    "A função **summarize** executa os seguintes passos:\n",
    "- Calcula a frequência das palavras no texto\n",
    "- Calcula a nota de cada sentença baseada na frequência de palavras.\n",
    "- Gera uma lista com as melhores sentenças descritas no texto original, ou seja, sem as exclusões realizadas na etapa do pré-processamento.\n",
    "\n",
    "Os seguintes parâmetros são passados para a função:\n",
    "- texto_original: conteúdo com o texto original, sem pré-processamento;\n",
    "- texto_formatado: texto original pré-processado;\n",
    "- quantidade_setencas: Número de sentenças que irão compor o resumo do texto.\n",
    "\n",
    "Observação: Este algoritmo considera que a quantidade de sentenças que irão compor o resumo corresponde a 40% do número total de sentenças do texto. (Esse valor pode ser alterado na etapa dos testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "186f7cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(texto_original, texto_formatado, quantidade_sentencas):\n",
    "    \n",
    "    # Cálculo das frequências das palavras\n",
    "    frequencia_palavras = nltk.FreqDist(nltk.word_tokenize(texto_formatado))\n",
    "    frequencia_maxima = max(frequencia_palavras.values())\n",
    "    \n",
    "    for palavra in frequencia_palavras.keys():\n",
    "        # Frequência proporcional das palavras\n",
    "        frequencia_palavras[palavra] = (frequencia_palavras[palavra] / frequencia_maxima)\n",
    "    lista_sentencas = nltk.sent_tokenize(texto_original)\n",
    "    \n",
    "    # Cálculo das notas das sentenças\n",
    "    nota_sentencas = {}\n",
    "    for sentenca in lista_sentencas:\n",
    "        for palavra in nltk.word_tokenize(sentenca.lower()):\n",
    "            if palavra in frequencia_palavras.keys():\n",
    "                if sentenca not in nota_sentencas.keys():\n",
    "                    nota_sentencas[sentenca] = frequencia_palavras[palavra]\n",
    "                else:\n",
    "                    nota_sentencas[sentenca] += frequencia_palavras[palavra]\n",
    "    \n",
    "    # Cálculo das melhores sentenças\n",
    "    melhores_sentencas = heapq.nlargest(quantidade_sentencas, nota_sentencas, key=nota_sentencas.get)\n",
    "    \n",
    "    return lista_sentencas, melhores_sentencas, nota_sentencas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4394212a",
   "metadata": {},
   "source": [
    "### 3.2. Definição da função view_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af0301d",
   "metadata": {},
   "source": [
    "A função **view_summary** exibe o sumário do texto resultante após a aplicação do algoritmo de sumarização. Esta função retorna as melhores sentenças com o texto original e concatenadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d68db0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_summary(lista_sentencas, melhores_sentencas):\n",
    "    texto = ''\n",
    "    \n",
    "    for sentenca in lista_sentencas:\n",
    "        if sentenca in melhores_sentencas:\n",
    "            texto = texto + ' ' + sentenca\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a774e6",
   "metadata": {},
   "source": [
    "### 3.3. Execução do Algoritmo para todas as notícias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ec1dfb",
   "metadata": {},
   "source": [
    "Esse trecho de código corresponde à execução completa do **Algoritmo de Frequência** para um lote de notícias. Os seguintes passos são executados:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bc9a8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "      <th>conteudo</th>\n",
       "      <th>sumario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "      <td>From her special numbers to TVappearances, Bol...</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotel staff to get training to spot signs of s...</td>\n",
       "      <td>Hotels in Mumbai and other Indian cities are t...</td>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3960</th>\n",
       "      <td>Rasna seeking ?250 cr revenue from snack categ...</td>\n",
       "      <td>Mumbai, Feb 23 (PTI) Fruit juice concentrate m...</td>\n",
       "      <td>Fruit juice concentrate maker Rasna is eyeing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3961</th>\n",
       "      <td>Sachin attends Rajya Sabha after questions on ...</td>\n",
       "      <td>Former cricketer Sachin Tendulkar was spotted ...</td>\n",
       "      <td>Former Indian cricketer Sachin Tendulkar atten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3962</th>\n",
       "      <td>Shouldn't rob their childhood: Aamir on kids r...</td>\n",
       "      <td>Aamir Khan, whose last film Dangal told the st...</td>\n",
       "      <td>Aamir Khan, while talking about reality shows ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3963</th>\n",
       "      <td>Asha Bhosle gets ?53,000 power bill for unused...</td>\n",
       "      <td>Maharahstra Power Minister Chandrashekhar Bawa...</td>\n",
       "      <td>The Maharashtra government has initiated an in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964</th>\n",
       "      <td>More than half of India's languages may die in...</td>\n",
       "      <td>More than half of the languages spoken by Indi...</td>\n",
       "      <td>At least 400 languages or more than half langu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3965 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 titulo  \\\n",
       "0     Daman & Diu revokes mandatory Rakshabandhan in...   \n",
       "1     Malaika slams user who trolled her for 'divorc...   \n",
       "2     'Virgin' now corrected to 'Unmarried' in IGIMS...   \n",
       "3     Aaj aapne pakad liya: LeT man Dujana before be...   \n",
       "4     Hotel staff to get training to spot signs of s...   \n",
       "...                                                 ...   \n",
       "3960  Rasna seeking ?250 cr revenue from snack categ...   \n",
       "3961  Sachin attends Rajya Sabha after questions on ...   \n",
       "3962  Shouldn't rob their childhood: Aamir on kids r...   \n",
       "3963  Asha Bhosle gets ?53,000 power bill for unused...   \n",
       "3964  More than half of India's languages may die in...   \n",
       "\n",
       "                                               conteudo  \\\n",
       "0     The Daman and Diu administration on Wednesday ...   \n",
       "1     From her special numbers to TVappearances, Bol...   \n",
       "2     The Indira Gandhi Institute of Medical Science...   \n",
       "3     Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
       "4     Hotels in Mumbai and other Indian cities are t...   \n",
       "...                                                 ...   \n",
       "3960  Mumbai, Feb 23 (PTI) Fruit juice concentrate m...   \n",
       "3961  Former cricketer Sachin Tendulkar was spotted ...   \n",
       "3962  Aamir Khan, whose last film Dangal told the st...   \n",
       "3963  Maharahstra Power Minister Chandrashekhar Bawa...   \n",
       "3964  More than half of the languages spoken by Indi...   \n",
       "\n",
       "                                                sumario  \n",
       "0     The Administration of Union Territory Daman an...  \n",
       "1     Malaika Arora slammed an Instagram user who tr...  \n",
       "2     The Indira Gandhi Institute of Medical Science...  \n",
       "3     Lashkar-e-Taiba's Kashmir commander Abu Dujana...  \n",
       "4     Hotels in Maharashtra will train their staff t...  \n",
       "...                                                 ...  \n",
       "3960  Fruit juice concentrate maker Rasna is eyeing ...  \n",
       "3961  Former Indian cricketer Sachin Tendulkar atten...  \n",
       "3962  Aamir Khan, while talking about reality shows ...  \n",
       "3963  The Maharashtra government has initiated an in...  \n",
       "3964  At least 400 languages or more than half langu...  \n",
       "\n",
       "[3965 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Leitura do arquivo JSON com a base de dados de notícias\n",
    "dt = pd.read_json(\"news.json\")\n",
    "display(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40f481c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin: 1635870196.4387906\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "Fim da execução: 1635870228.2936702\n",
      "Duração: 31.85487961769104\n"
     ]
    }
   ],
   "source": [
    "# Lista para armazenar o resultado do processamento do Algoritmo de frequência para todas as notícias\n",
    "algoritmo_frequencia = []\n",
    "processamento_frequencia = []\n",
    "\n",
    "inicio = time.time()\n",
    "processamento_frequencia.append({'Begin': inicio})\n",
    "print('Begin:', inicio)\n",
    "\n",
    "for i in range(len(dt)):\n",
    "    titulo = dt.iloc[i, 0]\n",
    "    conteudo = dt.iloc[i, 1]\n",
    "    sumario = dt.iloc[i, 2]\n",
    "    \n",
    "    # Geração de tokens (sentenças) com os textos originais\n",
    "    sentencas_originais = token_sentences(conteudo)\n",
    "    \n",
    "    # Executar o pre-processamento das sentenças para eliminar os caracteres e palavras irrelevantes\n",
    "    texto_formatado = preprocessamento(conteudo)\n",
    "    \n",
    "    # Quantidade de sentenças que irão compor o sumário: 20% do total de sentenças\n",
    "    quantidade_sentencas = math.ceil(len(sentencas_originais)*0.20)\n",
    "    \n",
    "    # Geração das melhores sentenças que irão compor o sumário do texto\n",
    "    lista_sentencas, melhores_sentencas, nota_sentencas = summarize(conteudo, texto_formatado, quantidade_sentencas)\n",
    "    \n",
    "    # Geração do sumário somente com as frases correspondentes às melhores sentenças do texto\n",
    "    sumario_frequencia = view_summary(sentencas_originais, melhores_sentencas)\n",
    "    \n",
    "    algoritmo_frequencia.append({'index': i, 'titulo': titulo, 'conteudo': conteudo, 'sumario': sumario, 'sumario_frequencia': sumario_frequencia})\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "\n",
    "fim = time.time()\n",
    "print('Fim da execução:', fim)\n",
    "processamento_frequencia.append({'End': fim})\n",
    "\n",
    "duracao = fim - inicio\n",
    "print('Duração:', duracao)\n",
    "processamento_frequencia.append({'Duration': duracao})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2addf394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Será criado um arquivo algoritmo_frequencia.json no mesmo diretório de execução do programa\n",
    "arquivo_gravar = os.path.join('algoritmo_frequencia.json')\n",
    "arquivo = open(arquivo_gravar, 'w+')\n",
    "arquivo.write(json.dumps(algoritmo_frequencia, indent=1))\n",
    "arquivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1f95845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Será criado um arquivo processamento_frequencia.json no mesmo diretório de execução do programa\n",
    "arquivo_gravar = os.path.join('processamento_frequencia.json')\n",
    "arquivo = open(arquivo_gravar, 'w+')\n",
    "arquivo.write(json.dumps(processamento_frequencia, indent=1))\n",
    "arquivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701a154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
